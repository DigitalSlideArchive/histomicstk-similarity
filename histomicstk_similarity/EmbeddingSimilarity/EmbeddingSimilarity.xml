<?xml version="1.0" encoding="UTF-8"?>
<executable>
  <category>HistomicsTK</category>
  <title>Embedding Similarity</title>
  <description>Calculate similarity within an image based on a feature embedding from different AI models</description>
  <version>1.0.0</version>
  <documentation-url>https://digitalslidearchive.github.io/HistomicsTK</documentation-url>
  <license>Apache 2.0</license>
  <contributor>David Manthey (Kitware Inc)</contributor>
  <acknowledgements>This work is part of the HistomicsTK project.</acknowledgements>
  <parameters>
    <label>Inputs</label>
    <description>Input parameters</description>
    <!-- We list the input image in two ways; the first ensures that the image is available so we can run feature embedding on the image if we haven't do so yet.  The second is the image id, so if we create an annotation we can upload it to the image directly; this is faster than uploading a file and then converting it to an annotation. -->
    <image>
      <name>image</name>
      <label>Input Image</label>
      <description>Input image</description>
      <channel>input</channel>
      <index>0</index>
    </image>
    <image reference="_girder_id_">
      <name>imageid</name>
      <longflag>imageid</longflag>
      <label>Input Image ID</label>
      <description>Input image ID</description>
      <channel>input</channel>
    </image>
    <!-- The embedding file is a numpy save file.  If present, we don't re-calculate the feature embedding on the image.  -->
    <file fileExtensions=".npz">
      <name>embedin</name>
      <label>Embedding Input File</label>
      <description>File with embeddings for image patches</description>
      <channel>input</channel>
      <longflag>embedin</longflag>
    </file>

    <string>
      <name>annotationid</name>
      <longflag>annotation</longflag>
      <label>Annotation ID</label>
      <description>If specified, this annotation will be modified.  If unspecified, a new annotation will be created</description>
      <default></default>
    </string>
    <region shapes="point,submitoff">
      <name>keypoint</name>
      <label>Key Point</label>
      <longflag>keypoint</longflag>
      <description>Key point for the similarity.  If -1,-1, no annotation is made or updated</description>
      <default>-1,-1</default>
    </region>
    <integer>
      <name>aggregate</name>
      <longflag>aggregate</longflag>
      <description>Number of patches to aggregate before comparison.  Larger values will, in theory, find larger features.</description>
      <label>Aggregation</label>
      <default>5</default>
    </integer>
    <double>
      <name>threshold</name>
      <longflag>threshold</longflag>
      <description>Minimum cosine similarity to appear on the heatmap [-1, 1]</description>
      <label>Plot Threshold</label>
      <default>0.75</default>
    </double>
    <string>
      <name>color</name>
      <longflag>color</longflag>
      <label>Color</label>
      <description>Primary color for heatmap</description>
      <default>#FFFF00</default>
    </string>
  </parameters>

  <parameters>
    <label>Generation</label>
    <description>Calculate embeddings based on a model.  This will only run if an Embedding Input File is not provided.</description>
    <string-enumeration>
      <name>model</name>
      <longflag>model</longflag>
      <description>Model to use if calculating embeddings</description>
      <label>Model</label>
      <default>Gigapath</default>
      <element>Gigapath</element>
      <element>UNI</element>
      <element>DinoV2Large</element>
      <element>Midnight</element>
      <element>Test</element>
    </string-enumeration>
    <integer>
      <name>tilesize</name>
      <longflag>tilesize</longflag>
      <description>Size of image patch to use for feature calculation</description>
      <label>Tile Size</label>
      <default>224</default>
    </integer>
    <integer>
      <name>stride</name>
      <longflag>stride</longflag>
      <description>Spacing between patch centers</description>
      <label>Analysis Stride</label>
      <default>112</default>
    </integer>
    <double>
      <name>scale_um</name>
      <longflag>scale_um</longflag>
      <description>Pixel scale in microns for tile sizes to send to the model.  0 for the default for model.</description>
      <label>Scale</label>
      <default>0</default>
    </double>
    <double>
      <name>magnification</name>
      <longflag>magnification</longflag>
      <description>Magnification for tile sizes to send to the model.  0 for the default for model.  If scale is non-zero, this is ignored.</description>
      <label>Magnification</label>
      <default>0</default>
    </double>
    <integer>
      <name>batch</name>
      <longflag>batch</longflag>
      <description>Batch size for sending data to torch.  If this is too large, the job will ask for use more memory than the GPU has.</description>
      <label>Batch Size</label>
      <default>16</default>
    </integer>
    <file fileExtensions=".npz">
      <name>embedout</name>
      <label>Embedding Output File</label>
      <description>File to store embeddings for image patches</description>
      <channel>output</channel>
      <longflag>embedout</longflag>
    </file>
  </parameters>

  <!-- These are used to allow sending annotations directly to girder -->
  <parameters advanced="true">
    <label>Girder API URL and Key</label>
    <description>A Girder API URL and token for Girder client</description>
    <string>
      <name>girderApiUrl</name>
      <longflag>api-url</longflag>
      <label>Girder API URL</label>
      <description>A Girder API URL (e.g., https://girder.example.com:443/api/v1)</description>
      <default></default>
    </string>
    <string>
      <name>girderToken</name>
      <longflag>girder-token</longflag>
      <label>Girder Token</label>
      <description>A Girder token</description>
      <default></default>
    </string>
  </parameters>
</executable>
